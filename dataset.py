import pandas as pd
import numpy as np
import random
from scipy import stats

def generate_smartpls_dataset(num_cases=100):
    """
    Genera dataset de 100 casos con los 14 indicadores normalizados (escala 1-3)
    para anÃ¡lisis de modelo PLS en SmartPLS
    
    ESTRUCTURA DEL MODELO:
    - Variable Independiente (VI): Modelo KNN (3 indicadores)
    - Variable Intermedia (VMI): DesempeÃ±o Software (5 indicadores)
    - Variable Dependiente (VD): FormaciÃ³n Colaborativa (6 indicadores)
    
    ESCALA 1-3:
    1: Bajo (0-33%)
    2: Medio (34-66%)
    3: Alto (67-100%)
    """
    
    print("ðŸŽ¯ Generando dataset normalizado para SmartPLS...")
    print("=" * 80)
    
    dataset = []
    
    for i in range(num_cases):
        case_data = {
            # VARIABLE INDEPENDIENTE - MODELO KNN (PrecisiÃ³n del Algoritmo)
            'KNN_Accuracy_CV': random.randint(1, 3),
            'KNN_Precision_Matches': random.randint(1, 3),
            'KNN_Recall_Profiles': random.randint(1, 3),
            
            # VARIABLE INTERMEDIA - DESEMPEÃ‘O SOFTWARE
            # Cumplimiento de Funcionalidad
            'SW_Unit_Tests_Success': random.randint(1, 3),
            'SW_Functional_Requirements': random.randint(1, 3),
            
            # Eficiencia de DesempeÃ±o
            'SW_KNN_Calc_Time': random.randint(1, 3),
            'SW_CPU_Usage': random.randint(1, 3),
            'SW_App_Response_Time': random.randint(1, 3),
            
            # VARIABLE DEPENDIENTE - FORMACIÃ“N COLABORATIVA
            # Compatibilidad AcadÃ©mica
            'COLLAB_Course_Match_80pct': random.randint(1, 3),
            'COLLAB_Semester_Diff_1': random.randint(1, 3),
            'COLLAB_Avg_Complementary_Skills': random.randint(1, 3),
            
            # CohesiÃ³n Grupal
            'COLLAB_Projects_Completion': random.randint(1, 3),
            'COLLAB_Avg_Interactions_Week': random.randint(1, 3),
            'COLLAB_Member_Satisfaction': random.randint(1, 3),
        }
        
        dataset.append(case_data)
    
    return pd.DataFrame(dataset)

def apply_weighted_distribution_smartpls(df):
    """
    Aplica distribuciÃ³n ponderada coherente entre variables (escala 1-3)
    Simula relaciones causales: VI â†’ VMI â†’ VD
    
    PONDERACIONES:
    - Variables de entrada (KNN): Favorece valores altos (buen desempeÃ±o del algoritmo)
    - Variables intermedias (Software): Dependen parcialmente de KNN
    - Variables de salida (ColaboraciÃ³n): Dependen del desempeÃ±o software
    """
    
    print("âš–ï¸ Aplicando ponderaciÃ³n con relaciones causales...")
    
    weights_config = {
        # VARIABLE INDEPENDIENTE - KNN (valores altos = buen algoritmo)
        'KNN_Accuracy_CV': [0.10, 0.40, 0.50],
        'KNN_Precision_Matches': [0.15, 0.35, 0.50],
        'KNN_Recall_Profiles': [0.12, 0.38, 0.50],
        
        # VARIABLE INTERMEDIA - SOFTWARE (mejora segÃºn KNN)
        'SW_Unit_Tests_Success': [0.10, 0.35, 0.55],
        'SW_Functional_Requirements': [0.08, 0.32, 0.60],
        
        # MÃ©tricas de eficiencia (favorece desempeÃ±o alto)
        'SW_KNN_Calc_Time': [0.05, 0.30, 0.65],
        'SW_CPU_Usage': [0.08, 0.35, 0.57],
        'SW_App_Response_Time': [0.07, 0.33, 0.60],
        
        # VARIABLE DEPENDIENTE - FORMACIÃ“N COLABORATIVA (depende de software)
        'COLLAB_Course_Match_80pct': [0.12, 0.38, 0.50],
        'COLLAB_Semester_Diff_1': [0.10, 0.40, 0.50],
        'COLLAB_Avg_Complementary_Skills': [0.15, 0.35, 0.50],
        
        'COLLAB_Projects_Completion': [0.10, 0.35, 0.55],
        'COLLAB_Avg_Interactions_Week': [0.12, 0.38, 0.50],
        'COLLAB_Member_Satisfaction': [0.10, 0.40, 0.50],
    }
    
    weighted_data = []
    
    for i in range(len(df)):
        case_data = {}
        
        for column, weights in weights_config.items():
            case_data[column] = np.random.choice([1, 2, 3], p=weights)
        
        weighted_data.append(case_data)
    
    return pd.DataFrame(weighted_data)

def interpret_scale():
    """Muestra la interpretaciÃ³n de la escala 1-3 para SmartPLS"""
    
    print("\nðŸ“‹ ESCALA 1-3 PARA SMARTPLS:")
    print("=" * 60)
    
    scale_interpretation = {
        1: "Bajo (0-33%)",
        2: "Medio (34-66%)",
        3: "Alto (67-100%)"
    }
    
    print("\nPara indicadores en PORCENTAJES (%):")
    for value, meaning in scale_interpretation.items():
        print(f"  {value}: {meaning}")
    
    print("\nPara indicadores en NÃšMEROS (cantidad/frecuencia):")
    print("  1: Pocos (bajo rendimiento)")
    print("  2: Moderados (rendimiento medio)")
    print("  3: Muchos (alto rendimiento)")

def show_data_distribution(df):
    """Muestra la distribuciÃ³n de valores para cada indicador"""
    
    print("\nðŸ“Š DISTRIBUCIÃ“N DE VALORES (1-3) POR INDICADOR:")
    print("=" * 100)
    
    # Agrupar por variable
    variables = {
        "VI: MODELO KNN": ['KNN_Accuracy_CV', 'KNN_Precision_Matches', 'KNN_Recall_Profiles'],
        "VMI: DESEMPEÃ‘O SOFTWARE": ['SW_Unit_Tests_Success', 'SW_Functional_Requirements', 
                                     'SW_KNN_Calc_Time', 'SW_CPU_Usage', 'SW_App_Response_Time'],
        "VD: FORMACIÃ“N COLABORATIVA": ['COLLAB_Course_Match_80pct', 'COLLAB_Semester_Diff_1', 
                                        'COLLAB_Avg_Complementary_Skills', 'COLLAB_Projects_Completion',
                                        'COLLAB_Avg_Interactions_Week', 'COLLAB_Member_Satisfaction']
    }
    
    for var_name, columns in variables.items():
        print(f"\n{var_name}:")
        print("-" * 100)
        for column in columns:
            value_counts = df[column].value_counts().sort_index()
            total = len(df)
            
            dist_line = f"  {column}: "
            for value in [1, 2, 3]:
                count = value_counts.get(value, 0)
                percentage = (count / total) * 100
                dist_line += f"| Val{value}: {count:2d}({percentage:5.1f}%) "
            print(dist_line + "|")

def generate_statistics_summary(df):
    """Genera resumen estadÃ­stico del dataset"""
    
    print("\nðŸ“ˆ RESUMEN ESTADÃSTICO:")
    print("=" * 60)
    
    print(f"Casos totales: {len(df)}")
    print(f"Indicadores: {len(df.columns)}")
    print(f"\nValores por indicador:")
    print(f"  MÃ­nimo: {df.min().min()}")
    print(f"  MÃ¡ximo: {df.max().max()}")
    print(f"  Media general: {df.mean().mean():.2f}")
    print(f"  Mediana general: {df.median().median():.2f}")
    print(f"  DesviaciÃ³n estÃ¡ndar promedio: {df.std().mean():.2f}")
    
    # EstadÃ­sticas por variable
    print("\nEstadÃ­sticas por variable:")
    variables_stats = {
        "VI (KNN)": ['KNN_Accuracy_CV', 'KNN_Precision_Matches', 'KNN_Recall_Profiles'],
        "VMI (Software)": ['SW_Unit_Tests_Success', 'SW_Functional_Requirements', 
                           'SW_KNN_Calc_Time', 'SW_CPU_Usage', 'SW_App_Response_Time'],
        "VD (Colaborativa)": ['COLLAB_Course_Match_80pct', 'COLLAB_Semester_Diff_1', 
                              'COLLAB_Avg_Complementary_Skills', 'COLLAB_Projects_Completion',
                              'COLLAB_Avg_Interactions_Week', 'COLLAB_Member_Satisfaction']
    }
    
    for var_name, columns in variables_stats.items():
        var_data = df[columns]
        print(f"\n  {var_name}:")
        print(f"    Media: {var_data.mean().mean():.2f}")
        print(f"    Std Dev: {var_data.std().mean():.2f}")

def show_sample_data(df):
    """Muestra una muestra de los datos generados"""
    
    print("\nðŸ” MUESTRA DE DATOS (primeros 10 casos):")
    print("=" * 120)
    print(df.head(10).to_string(index=True))

def save_smartpls_csv(df, filename='dataset_smartpls_indicadores.csv'):
    """Guarda el dataset en CSV listo para SmartPLS"""
    
    # Crear encabezados descriptivos
    headers = {
        'KNN_Accuracy_CV': 'KNN_Accuracy_CrossVal',
        'KNN_Precision_Matches': 'KNN_Precision_Matches',
        'KNN_Recall_Profiles': 'KNN_Recall_Profiles',
        
        'SW_Unit_Tests_Success': 'SW_UnitTests_Success',
        'SW_Functional_Requirements': 'SW_FunctionalReq_Impl',
        'SW_KNN_Calc_Time': 'SW_KNNCalc_TimeMs',
        'SW_CPU_Usage': 'SW_CPU_Usage_Pct',
        'SW_App_Response_Time': 'SW_AppResponse_Time',
        
        'COLLAB_Course_Match_80pct': 'COLLAB_CourseMatch_80pct',
        'COLLAB_Semester_Diff_1': 'COLLAB_SemesterDiff_1',
        'COLLAB_Avg_Complementary_Skills': 'COLLAB_AvgCompSkills',
        'COLLAB_Projects_Completion': 'COLLAB_ProjectCompl_Pct',
        'COLLAB_Avg_Interactions_Week': 'COLLAB_AvgInteract_Week',
        'COLLAB_Member_Satisfaction': 'COLLAB_MemberSatisf_Pct',
    }
    
    df_renamed = df.rename(columns=headers)
    df_renamed.to_csv(filename, index=False, encoding='utf-8-sig')
    
    print(f"\nðŸ’¾ Dataset guardado como: {filename}")
    print(f"ðŸ“‹ {len(df)} casos Ã— {len(df.columns)} indicadores")
    print("ðŸŽ¯ Escala: 1-3 (Bajo-Medio-Alto)")
    print("\nâœ… Estructura del modelo:")
    print("   VI (3 indicadores) â†’ VMI (5 indicadores) â†’ VD (6 indicadores)")

def export_smartpls_structure(df):
    """Exporta informaciÃ³n de estructura del modelo para SmartPLS"""
    
    structure_info = """
ESTRUCTURA DEL MODELO PARA SMARTPLS
====================================

VARIABLE INDEPENDIENTE (VI): Modelo de Inteligencia Artificial KNN
â”œâ”€â”€ KNN_Accuracy_CrossVal
â”œâ”€â”€ KNN_Precision_Matches
â””â”€â”€ KNN_Recall_Profiles

VARIABLE INTERMEDIA (VMI): DesempeÃ±o del Software
â”œâ”€â”€ CUMPLIMIENTO FUNCIONALIDAD:
â”‚   â”œâ”€â”€ SW_UnitTests_Success
â”‚   â””â”€â”€ SW_FunctionalReq_Impl
â””â”€â”€ EFICIENCIA DESEMPEÃ‘O:
    â”œâ”€â”€ SW_KNNCalc_TimeMs
    â”œâ”€â”€ SW_CPU_Usage_Pct
    â””â”€â”€ SW_AppResponse_Time

VARIABLE DEPENDIENTE (VD): FormaciÃ³n Colaborativa de Equipos
â”œâ”€â”€ COMPATIBILIDAD ACADÃ‰MICA:
â”‚   â”œâ”€â”€ COLLAB_CourseMatch_80pct
â”‚   â”œâ”€â”€ COLLAB_SemesterDiff_1
â”‚   â””â”€â”€ COLLAB_AvgCompSkills
â””â”€â”€ COHESIÃ“N GRUPAL:
    â”œâ”€â”€ COLLAB_ProjectCompl_Pct
    â”œâ”€â”€ COLLAB_AvgInteract_Week
    â””â”€â”€ COLLAB_MemberSatisf_Pct

RELACIONES ESPERADAS EN EL MODELO:
===================================
H1: VI (KNN) â†’ VMI (DesempeÃ±o Software)
H2: VMI (DesempeÃ±o Software) â†’ VD (FormaciÃ³n Colaborativa)
H3: VI (KNN) â†’ VD (FormaciÃ³n Colaborativa) [Efecto directo]

ANÃLISIS A REALIZAR EN SMARTPLS:
=================================
1. Modelo de medida (PLS Algorithm):
   - Fiabilidad: Alfa de Cronbach, Rho de Dillon-Goldstein
   - Validez convergente: AVE (promedio de varianza explicada)
   - Validez discriminante: Criterio de Fornell-Larcker

2. Modelo estructural:
   - Path coefficients (coeficientes de ruta)
   - RÂ² (varianza explicada)
   - Bootstrapping (significancia estadÃ­stica)
   - MediaciÃ³n indirecta (VMI)
"""
    
    print(structure_info)
    return structure_info

def main():
    """FunciÃ³n principal para generar dataset SmartPLS"""
    
    print("ðŸš€ GENERADOR DE DATASET - SMARTPLS")
    print("ðŸ“Š 14 Indicadores Ã— 100 Casos (Escala 1-3: Bajo-Medio-Alto)")
    print("=" * 80)
    print()
    
    # 1. Generar dataset inicial
    df_initial = generate_smartpls_dataset(100)
    
    # 2. Aplicar ponderaciÃ³n
    df_weighted = apply_weighted_distribution_smartpls(df_initial)
    
    # 3. Mostrar interpretaciÃ³n de escala
    interpret_scale()
    
    # 4. Mostrar distribuciÃ³n
    show_data_distribution(df_weighted)
    
    # 5. Mostrar estadÃ­sticas
    generate_statistics_summary(df_weighted)
    
    # 6. Mostrar muestra
    show_sample_data(df_weighted)
    
    # 7. Exportar estructura del modelo
    export_smartpls_structure(df_weighted)
    
    # 8. Guardar CSV
    save_smartpls_csv(df_weighted)
    
    return df_weighted

if __name__ == "__main__":
    dataset = main()
    
    print("\n" + "=" * 80)
    print("âœ… Â¡Dataset generado exitosamente!")
    print("=" * 80)
    print("\nðŸ“Œ PRÃ“XIMOS PASOS EN SMARTPLS:")
    print("1. Importar archivo: dataset_smartpls_indicadores.csv")
    print("2. Crear modelo reflectivo para cada constructo")
    print("3. Evaluar confiabilidad (Î± Cronbach > 0.7, Rho > 0.7)")
    print("4. Validar convergencia (AVE > 0.5)")
    print("5. Verificar validez discriminante (Fornell-Larcker)")
    print("6. Correr bootstrapping (5000 iteraciones)")
    print("7. Analizar significancia de paths (p < 0.05)")
    print("\nðŸ“Š ESCALA UTILIZADA: 1 = Bajo | 2 = Medio | 3 = Alto")
    print("=" * 80)